{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the Naive Bayes Classifier\n",
    "\n",
    "Let's first create the **bag of words** from the [IMDB dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). We'll redo all these lectures in the end with the messages corpus just for fun, for education instead stick to something more serious.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset_filepath = \"../datasets/IMDB.csv\"\n",
    "messages_dataset_filepath = \"../datasets/train.csv\"\n",
    "\n",
    "#imdb_dataset = pd.read_csv(imdb_dataset_filepath)\n",
    "imdb_dataset = pd.read_csv(messages_dataset_filepath)\n",
    "\n",
    "print(imdb_dataset)\n",
    "#print(f\"total examples={len(imdb_dataset)}\")\n",
    "#print(f\"positive examples={len(imdb_dataset[imdb_dataset['sentiment'] == 'positive'])}\")\n",
    "#print(f\"negative examples={len(imdb_dataset[imdb_dataset['sentiment'] == 'negative'])}\")\n",
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P^(c) = Nc/ Ndoc*\n",
    "so in our case for `positive` it's = 25000 / 50000 = 1/2. Same for `negative`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bag of words from the imdb corpus\n",
    "def get_bag_of_words(dataset):\n",
    "  bag_of_words = set()\n",
    "  for row in dataset.iterrows():\n",
    "    review = row[1]\n",
    "    review = review.str.split(\" \")\n",
    "    review = review.to_list()[0]\n",
    "    for word in review:\n",
    "      bag_of_words.add(word)\n",
    "  #print(review)\n",
    "  return bag_of_words\n",
    "\n",
    "#print(bag_of_words)\n",
    "#print(len(bag_of_words))\n",
    "#for word in bag_of_words:\n",
    "#  print(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P(wi|c)* is the fraction of times the word *wi* appears among all words in all documents of topic c.\n",
    "\n",
    "We first concatenate all documents with category c into one big “category c” text.\n",
    "\n",
    "Then we use the frequency of *wi* in this concatenated document to give a maximum likelihood estimate of probability:\n",
    "\n",
    "![alt text](../images/mle_concatenated_documents.png)\n",
    "\n",
    "\n",
    "Here the vocabulary *V* consists of all the word types in all classes, not just the words in class *c*.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_of_topic_positive = imdb_dataset[imdb_dataset[\"block\"] == 0]\n",
    "documents_of_topic_negative = imdb_dataset[imdb_dataset[\"block\"] == 1]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents_of_topic_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents_of_topic_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_in_positive_documents = get_bag_of_words(documents_of_topic_positive)\n",
    "bag_of_words_in_positive_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_in_negative_documents = get_bag_of_words(documents_of_topic_negative)\n",
    "bag_of_words_in_negative_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue with MLE training. Imagine we try to estimate the likelihood of the word \"fantastic\" given the class \"positive\", but no training documents that contain the word \"fantastic\" and is classified as \"positive\". Perhaps \"fantastic\" used in a *sarcastic* way in *negative* class. In this case the probability would be 0.\n",
    "\n",
    "![alt text](../images/sarcastic_probability.png)\n",
    "\n",
    "Since naive Bayes multiplies all the feature likelihoods together, zero probabilities in the likelihood term for any class will cause the probability of the class to be zero, no matter the other evidence!\n",
    "\n",
    "The simples solution is to add the Laplace add-one smoothing, this one is commonly used in naive Bayes rather than language models.\n",
    "\n",
    "![alt text](../images/naive_bayes_add_laplace.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V is our vocabulary\n",
    "V = bag_of_words_in_positive_documents.union(bag_of_words_in_negative_documents)\n",
    "V_sure = get_bag_of_words(imdb_dataset)\n",
    "assert V == V_sure, f\"expected {len(V_sure)} but got {len(V)}\"\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do about **unknown** words? i.e. words that did not occur in the training document of any class and are not in our vocabulary but did appear in the test data.\n",
    "\n",
    "The solution for this is to ignore them. Remove them from the test document and not include any probability for them at all. TODO why is this the case???\n",
    "\n",
    "\n",
    "Some systems may choose to ignore another class of words: **stop words**, very frequent words like *the* and *a*. Sort the vocabulary and remove the top 10-100 vocabulary entries as stop words or use already predefined online. Then each istance of these is removed from both test and training documents as if it never occurred.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Worked example\n",
    "let's calculate the *P(c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_examples = len(imdb_dataset)\n",
    "positive_example_counts = len(imdb_dataset[imdb_dataset[\"sentiment\"] == \"positive\"])\n",
    "negative_example_counts = len(imdb_dataset[imdb_dataset[\"sentiment\"] == \"negative\"])\n",
    "prior_positive_class = positive_example_counts / total_examples\n",
    "prior_negative_class = negative_example_counts / total_examples\n",
    "\n",
    "print(f\"prior_positive_class={prior_positive_class}\")\n",
    "print(f\"prior_negative_class={prior_negative_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../images/prior_likelihood_features.png)\n",
    "\n",
    "to apply Naive Bayes classifier to text, we will use each word in the documents as a feature and we consider each of the words in the document by walking an index through every word position in the document.\n",
    "\n",
    "![alt text](../images/position_words.png)\n",
    "    \n",
    "\n",
    "Naive Bayes calculations are done in log space for same reason explained earlier.\n",
    "\n",
    "![alt text](../images/naive_bayes_log.png)\n",
    "\n",
    "#### Training the Naive Bayes Classifier\n",
    "How can we learn the probabilities of *P(c)* i.e. the *prior* and *P(fi|c)* i.e. *likelihood*?\n",
    "\n",
    "First we'll consider the MLE. Simply use the frequencies in the data. For the class prior *P(c)* we ask which percentage of the documents in our training data class *c* and the *Ndoc*be the total number of documents. Then:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO try this at some point potentially filter stop words\n",
    "#from sklearn.feature_extraction import text\n",
    "#stop_words = set(text.ENGLISH_STOP_WORDS)\n",
    "def get_bag_of_words(dataset):\n",
    "  return set(\n",
    "    dataset[\"text\"] # access all the text column\n",
    "    .dropna()       # remove missing values\n",
    "    #.str.lower()\n",
    "    .str.split()    # split on whitespaces (more efficient than \" \")\n",
    "    .explode()      # flatten all words into one Series\n",
    "    #.loc(lambda x: ~x.isin(stop_words)) # filter stopwords early\n",
    "  )\n",
    "\n",
    "\n",
    "# we're keeping the punctuation and everything and just considering the\n",
    "# words as split by whitespaces so some of these results may not be accurate\n",
    "def train_naive_bayes():\n",
    "  total_examples = len(imdb_dataset)\n",
    "  positive_example_counts = len(imdb_dataset[imdb_dataset[\"block\"] == 0])\n",
    "  negative_example_counts = len(imdb_dataset[imdb_dataset[\"block\"] == 1])\n",
    "\n",
    "  prior_positive_class = np.log2(positive_example_counts/total_examples)\n",
    "  prior_negative_class = np.log2(negative_example_counts/total_examples)\n",
    "\n",
    "  print(prior_positive_class, prior_negative_class)\n",
    "\n",
    "  # compute the vocabulary V\n",
    "  bag_of_words_in_negative_documents = get_bag_of_words(documents_of_topic_negative)\n",
    "  bag_of_words_in_positive_documents = get_bag_of_words(documents_of_topic_positive)\n",
    "  V = bag_of_words_in_positive_documents.union(bag_of_words_in_negative_documents)\n",
    "  V_sure = get_bag_of_words(imdb_dataset)\n",
    "  assert V == V_sure, f\"expected {len(V_sure)} but got {len(V)}\"\n",
    "\n",
    "  bigdoc = {\n",
    "    \"positive\": \" \".join(documents_of_topic_positive[\"text\"].astype(str)),\n",
    "    \"negative\": \" \".join(documents_of_topic_negative[\"text\"].astype(str)),\n",
    "  }\n",
    "\n",
    "  # precompile a regex pattern to match all words in V\n",
    "  sorted_words = sorted(V, key=lambda x: (-len(x), x))\n",
    "  pattern_str = r'\\b' + '|'.join([re.escape(word) for word in sorted_words]) + r'\\b'\n",
    "  word_regex = re.compile(pattern_str)\n",
    "\n",
    "  def count_words(text): return Counter(word_regex.findall(text))\n",
    "\n",
    "  # do we really need to do it this way???\n",
    "  positive_counts = count_words(bigdoc[\"positive\"])\n",
    "  negative_counts = count_words(bigdoc[\"negative\"])\n",
    "\n",
    "  # build counts dictionary\n",
    "  counts = {}\n",
    "  for word in V:\n",
    "    counts[(word, \"positive\")] = positive_counts.get(word, 0)\n",
    "    counts[(word, \"negative\")] = negative_counts.get(word, 0)\n",
    "\n",
    "  return V, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V, counts = train_naive_bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(V)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts)\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
